<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Boot on My First Website</title>
    <link>/tags/boot/</link>
    <description>Recent content in Boot on My First Website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 01 Nov 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/boot/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Resampling Method</title>
      <link>/2018/11/01/resampling-method/</link>
      <pubDate>Thu, 01 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/11/01/resampling-method/</guid>
      <description>重抽样方法 1.验证集方法(validation set approach) 1.随机的把观测集分成两部分:一个训练集(training set)和一个验证集(validation set)[保留集(hold-out set)].
模型在训练集上拟合,然后用拟合的模型来预测验证集中观测的响应变量,得到的验证集错误率(通常用均方误差)作为定量响应变量的误差度量,提供了对测试错误率的一个估计.
2.缺陷:
测试错误率因为验证集的选取不同波动很大
只有训练集中的观测被用于拟合模型,验证集错误率会高估在整个数据集上拟合模型所得到的测试错误率.
 2.留一交叉验证法(leave-one-out cross-validation, LOOCV) 1.将单独的一个观测作为验证集\((x_1,y_1)\),剩下的观测组成训练集拟合模型,再用\((x_1,y_1)\)验证,对每个观测重复这一步骤,得到n个MSE:\[CV_{(n)}=\frac{1}{n}\sum_{i=1}^{n}{MSE_i}\] \(CV_{(n)}\)是测试均方误差的无偏估计.
2.优点:1.偏差较小,不容易高估测试误差率.2.LOOCV方法不存在随机性 缺点:计算量大. 3.用最小二乘法拟合线性回归或多项式回归时,可简化为:\[CV_{(n)}=\frac{1}{n}\sum_{i=1}^{n}{(\frac{y_i-\hat{y_i}}{1-h_i})^{2}}\] \(h_i\)是杠杆值:\[h_i=\frac{1}{n}+\frac{(x_i-\overline{x})^{2}}{\sum_{i^{&amp;#39;}=1}^{n}{(x_{i^{&amp;#39;}}-\overline{x})^{2}}}\] \(h_i\)的取值在\(\frac{1}{n}\)和1之间,若远远超过\(\frac{p+1}{n}\),则对应点有较高的杠杆作用.
 3.k折交叉验证法(k-fold CV) 1.将观测分为k个大小基本一致的组(或者说折fold),第一折作为验证集,然后在剩下的k-1折拟合模型,重复这个步骤k次,每一次把不同的观测组作为验证集,会得到k个测试误差的估计(MSE),k折CV估计用这些值求平均得到:\[CV_{(k)}=\frac{1}{k}\sum_{i=1}^{k}{MSE_i}\] 一般令k=5或k=10.
2.优点:1.计算量小.2.对测试误差的估计通常更准确.
偏差-方差权衡问题:LOOCV的每一个模型高度相关,k折CV的方法相对的相关性低,高度相关的量的均值要比相关性较小的量的均值具有更高的波动性,因此LOOCV对测试均方误差的估计虽然偏差更小但方差更大.
 4.分类问题 分类问题用错误率替代均方误差:\[CV_{(n)}=\frac{1}{n}\sum_{i=1}^{n}{Err_i}\] 其中\(Err_i=I(y_i≠\hat{y_i})\).
 5.自助法(bootstrap) 自助法通过反复从原始数据集中抽取观测得到数据集:抽样通过有放回的形式进行,抽样得到\(Z^{*1}\),每次抽样结束后对参数进行估计,得到估计值\(\hat{\alpha^{*1}}\),这个步骤重复B次,其中B是一个很大的值,就可以产生B个数据集和相应的估计值,用这些估计值的均值来估计\(\hat{\alpha}\).
  </description>
    </item>
    
  </channel>
</rss>